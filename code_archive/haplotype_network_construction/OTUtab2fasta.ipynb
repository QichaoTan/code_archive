{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GLOBAL VARIABLES\n",
    "\n",
    "#LENGTH SELECTION\n",
    "min_length = 195\n",
    "max_length = 205\n",
    "\n",
    "#PRIMER\n",
    "forward_primer = 'TTGCTTGGGTTTTTCAGCGT'\n",
    "reverse_primer = 'GCCGCAAGTTTAACTCCAACA'\n",
    "\n",
    "#PATH\n",
    "df = pd.read_csv('//home/qichaotan/CODE_ARCHIVE/code_archive/haplotype_network_construction/COX3_ASV_table.csv') #Input OTU table, csv format, column: Sequence, row: Sample name\n",
    "file_list = os.listdir('/home/qichaotan/COX3_dada2') # Original sample names, convert sample names to indexes, in order to shorten the name for phylip files. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mapper from sample name to index\n",
    "site2index = dict()\n",
    "for i in file_list:\n",
    "    location_info = i.split('_')\n",
    "    site2index.update({location_info[0]:location_info[1]})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASV_list = df.columns.to_list()[1:]\n",
    "\n",
    "#Clean out sample based on length\n",
    "ASV_list = [seq for seq in ASV_list if len(seq) >= min_length and len(seq) <= max_length and seq.startswith(forward_primer) == True and seq.endswith(reverse_primer) == True]\n",
    "\n",
    "ASV_alias = []\n",
    "for i in range(len(ASV_list)):\n",
    "    ASV_alias.append(str('ASV'+str(i+1)))\n",
    "ASV_mapper = dict(zip(ASV_list, ASV_alias))\n",
    "ASV_reverse_mapper = dict(zip(ASV_alias, ASV_list))\n",
    "df.rename(columns = {'Unnamed: 0':'Site'}, inplace=True)\n",
    "ASV_list.insert(0,'Site')\n",
    "df = df[ASV_list]\n",
    "df.rename(columns = ASV_mapper, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('COX3_ASV_soft.fasta', 'w') as output_handle:\n",
    "    for i in df['Site'].to_list()[1:]:\n",
    "        temp_df = df[df['Site'] == i]\n",
    "        for j in ASV_alias:\n",
    "            if temp_df[j].values != 0:\n",
    "                record = SeqRecord(\n",
    "                    Seq(str(ASV_reverse_mapper[j])),\n",
    "                    id = str(j) + '_' + str(site2index[i]),\n",
    "                    description = \"Emiliania huxleyi COX3 gene\" + ' ' + str(j) \n",
    "                )\n",
    "                SeqIO.write(record, output_handle, 'fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('COX3_ASV_hard.fasta', 'w') as output_handle:\n",
    "    for key, value in ASV_reverse_mapper.items():\n",
    "        record = SeqRecord(\n",
    "            Seq(str(value)),\n",
    "            id = key,\n",
    "            description = \"Emiliania huxleyi COX3 gene\" + ' ' + str(key)\n",
    "        )\n",
    "        SeqIO.write(record, output_handle, 'fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Cleaned_ASV_table.csv','w') as output_handle:\n",
    "    df.to_csv(output_handle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
